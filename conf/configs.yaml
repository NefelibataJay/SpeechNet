datasets:
  only_one_set: False
  manifest_path: /data_disk/zlf/code/jModel/conformer-rnnt/manifest/
  dataset_path: /datasets/aishell/data_aishell/
  feature_types: fbank
  num_mel_bins: 80
  spec_agument: True


tokenizer:
  lang: zh
  word_dict_path: D:\model\rnn-t\manifest\vocab.txt

datamodule:
  batch_size: ${training.batch_size}
  num_workers: 0

logger:
  save_dir: tb_logs
  name: model_logs

model:
  num_classes: ??
  input_dim: 80 # 80 for fbank
  encoder_dim: 512
  num_encoder_layers: 12
  num_attention_heads: 8
  feed_forward_expansion_factor: 4
  conv_expansion_factor: 2
  input_dropout_p: 0.1
  feed_forward_dropout_p: 0.1
  attention_dropout_p: 0.1
  conv_dropout_p: 0.1
  conv_kernel_size: 31
  half_step_residual: True

  decoder_output_dim: ${model.encoder_dim}
  hidden_state_dim: 320
  decoder_num_layers: 1

  freq_masks: 2
  time_masks: 10
  freq_width: 27
  time_width: 0.05

  rnn_type: lstm
  sos_id: 1
  eos_id: 2

  grad_ckpt_batchsize: 4


training:
  batch_size: 24
  max_epoch: 50

optimizer:
  optimizer_name: adam
  betas: [ 0.9, 0.98 ]
  weight_decay: 1e-3


lr_scheduler:
  lr: 0.001
  #  scheduler_name: None
  #  gamma: 0.1
  last_epoch: ${training.max_epoch}

  num_warmup_steps: 4000
  num_training_steps: 100000



trainer:
  max_epochs: ${training.max_epoch}
  enable_progress_bar: True
  accelerator: auto
  detect_anomaly: True
  accumulate_grad_batches: 8
  gradient_clip_val: 5.0


ckpt:
  have_ckpt: False
  ckpt_path: "/data_disk/zlf/code/jModel/conformer-rnnt//checkpoint/conformer_rnnt.ckpt"
  save_path: "/data_disk/zlf/code/jModel/conformer-rnnt//checkpoint/conformer_rnnt_common.ckpt"
  train: True
